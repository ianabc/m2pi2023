{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numpy\n",
    "\n",
    "[Numpy](https://www.numpy.org/) is the foundation of most of what you will do with scientific python. Modules like [scipy](https://www.scipy.org/), [pandas](https://pandas.pydata.org/) and [scikit-learn](https://scikit-learn.org/stable/) are built on top of numpy. It is the _linga franca_ for numerical work in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you are first introduced to Python, one of the big selling points is that it isn't statically typed (dynamic/strong). You can do things like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "a = 'apple'\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you won't get complaints from python about a being an integer. This is a _big_ advantage for python, and it works with collections as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myList = [1, 3., 'Ian', [range(3)], {'not': 'a good idea'}, lambda x: x**2, object ]\n",
    "myList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists in python are about as general as they could be. This is very flexible and it lets you do some fancy things, but it has a price. The Python interpreter can't make any assumptions about what will come next in a list; everything has to be treated as a generic object. Python does a good job of hiding the complexity of doing this, but as the lists get longer and more complex the overhead gets larger, and eventually perfomance becomes unacceptable.\n",
    "\n",
    "One solution to this is to use a statically typed language like C[<sup>1</sup>](#fn1 \"footnote and tooltip 1\"). There the burden of figuring out object types is left to the programmer, and the compiler can be much more efficient operating on them. A good example would be an array of `double`s. In memory, these will be allocated contiguously so when you need to jump to the 1402th double, you can do it with very simple arithmetic. Python has a much harder time because the memory allocated for your list could be a horrible mixture of all the different things you've stuffed in there. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The `ndarray`\n",
    "\n",
    "Numpy attempts to keep the advantages of Python without sacrificing the speed of static typing by adding the concept of homogeneous collections to python: `ndarray`s. The `ndarray` is the foundational concept in numpy, it is an array object which represents a multidimensional, homogeneous array of fixed-size items and most commonly these items will be numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "for i in range(1000000):\n",
    "    i*i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.arange(1000000)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ndarray`s look like python lists, but they are fundamentally different, e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2, 3, 4]\n",
    "b = [5, 6, 7, 8]\n",
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.array([1, 2, 3, 4])\n",
    "nb = np.array([5, 6, 7, 8])\n",
    "na + nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` was able to assume that the things in the `ndarray` were the compatible types and vectorize the addition, if we want the same thing with python lists, we have to jump through some hoops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ i + j for i, j in zip(a, b) ] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "_If you dig deep enough in some of the numpy/scipy code you will find that the actual instructions you are executing were compiled from fortran and C. In general you can pass things quite easily between existing libraries and python, but fortran and C use different storage orders for multi-dimensional arrays so you have to be a little bit careful_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what actually makes up an `ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na = np.array([1,2,3,4,5])\n",
    "na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_names = [attr_name for attr_name in dir(np.ndarray)\n",
    "              if not callable(getattr(np.ndarray, attr_name)) \n",
    "              and not attr_name[:2] == '__']\n",
    "\n",
    "attr_help = {a : getattr(np.ndarray, a).__doc__.split('\\n')[0] for a in attr_names}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using these attributes, numpy can use some of the same tricks that statically typed languges use because the Python interpreter can now infer the memory layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10, dtype=float)\n",
    "a.nbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attributes allow us to look at the same object in memory in multiple ways. `numpy` calls this concept a `view` of the original `ndarray`. Wherever possible, numpy will always try to use views rather than copying data. This is important to numpy's efficiency, but you have to remember that modifications will alter all views,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a[::2]\n",
    "b.base is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a.reshape(5,2)\n",
    "c[3,0] = -1\n",
    "c.base is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = a[[0, 3, 7]]\n",
    "d.base is a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.astype(int).base is a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `ndarray`s\n",
    "numpy has some convenience methods for creating new `ndarray`s. As you saw above, one way to create an ndarray is to pass a iterable with the values to `np.array`. Here are some others...\n",
    "\n",
    "Using `np.array` directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array([1, 2, 3, 4, 5, 6])\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.arange` will generate numbers between limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = np.arange(0, 100)\n",
    "a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a22 = np.arange(0, 10, dtype=float)\n",
    "a22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.linspace` is very useful, you tell it where to start and stop and how many samples you need and linspace does the rest. Here we will create numbers 100 numbers between 0 and 1 (inclusive), linearly spaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li1 = np.linspace(0, 1, 20)\n",
    "li1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Exercise: Use linspace to generate 25 of the values between 1 and 5, excluding the endpoint_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.zeros` and `np.ones` functions will generate an `ndarray` full of those values. The first argument is the shape which you can give as an integer (for 1d arrays) or a sequence (for n-dimensional arrays). You can also pass the `dtype=` argument to tell it what type of number you are looking for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z1 100 integer zeros\n",
    "z1 = np.zeros(100, dtype=int)\n",
    "\n",
    "# z2 a 5,5 array of float64 zeros\n",
    "z2 = 5 * np.ones((5, 5), dtype='complex128')\n",
    "z2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.eye` function generates a 2D array with ones down the diagonal, zeros elsewhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e1 a 5x5 array with ones down the diagonal\n",
    "e1 = np.eye(5, dtype=np.float64)\n",
    "e1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Exercise**: The diag function lets you specify diagonal arrays by giving the non-zero entries down the diagonal. Try creating a 5x5 array with ones down the diagonal. Have a look at the help and see if you can do the same thing with the ones offset above and below the diagonal_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll discuss the `numpy.random` module in detail later on, but for now, it has some useful convenience methods. `np.random.randint` returns random integers. Take a look at the help on the method then create a name `r1` with an array of `4x5` random numbers between `0` and `10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r1 a 4x5 array of random integers between 0 & 10, \n",
    "np.random.randint(0, 10, size=(4, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy floats have representations for certain special values `np.nan`, `np.Inf` etc. These objects have well defined comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.NaN == np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.NINF < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.NAN < np.Infinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Slicing\n",
    "\n",
    "Now that we have some `ndarray`s to play with, lets look at using them. Of course, `ndarray`s are zero indexed and for simple operations, slicing works as it normally does in Python, but since slices can be represented as a `view`, numpy doesn't copy the array when returning a slice, it returns a view. If you _really_ need a new array, the `.copy()` method will do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First element of a2\n",
    "a2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd to last element of a2\n",
    "a2[-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can update `ndarray` in place by index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2[-1] = 0\n",
    "a2[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values between 3 and 19 of a2\n",
    "a2[3:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every third value between 3 and 19\n",
    "a2[3:19:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using negative is allowed for all three parts of the slice, but for the step you have to think a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values between -10 and -2\n",
    "a2[-10:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first argument of the slice is still inclusive and the second is not. If we omit a value when specifying the slice `start` defaults to 0, `end` defaults to the last element and `step` defaults to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2[::3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multi-dimensional arrays the indexing notation is similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(100)\n",
    "b.shape = (10, 10)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about row 0, column 3 (remember python is 0 indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[0,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or the fifth column of the first two rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Exercise**: Create a 2d array with 1 on the border and 0 inside_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fancy Indexing\n",
    "\n",
    "Fancy Indexing is the idea of using another array of indices, it is useful when the combinations you want to select become a bit more complicated. We'll see more of this in pandas but as a few quick examples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=np.arange(27)[::-1]\n",
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v1[[1, 4, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2 = v1.reshape(3,9)\n",
    "v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In higher dimensions think of `zip`-ping together the arguements, e.g. first row (index 0), fourth column (index 3) column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v2[[0, 1, 1], [3, 7, 8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also index with logical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(42)\n",
    "ar = rng.integers(0, 10, size=25)\n",
    "\n",
    "# Negate any values between 3 and 8\n",
    "ar[(3 < ar) & (ar < 8)] *= -1\n",
    "ar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `np.argmax` and `np.argmin` functions can return the maximum or minimum value along some axis and can be used together with fancy indexing to grab values of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar.shape = (5,5)\n",
    "np.argmax(ar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`argmax` returns the index for a flattened copy of the array, but the `unravel_index` function can help us translate that to the position we actually want (I'm deliberately ignoring functions like `max` here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ar[np.unravel_index(np.argmax(ar), ar.shape)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*N.B. Fancy indexing usually creates copies of the `ndarray` because you usually can't reconstruct the selection with simple algebra*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Arrays\n",
    "\n",
    "Sometimes it is convenient to reshape arrays. I did this above by setting the `.shape` attribute but numpy arrays also have a reshape method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.arange(27)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`reshape` expects a sequence as the first argument (e.g. a tuple) so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = c.reshape((3, 9))\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One argument to reshape can be `-1`, in which case the number is determined by the number and size of remaining dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 256x256 array of pixels with values between 0 and 4 reshaped to 2 dimensional\n",
    "w, h = 256, 256\n",
    "I = np.random.randint(0, 4, (h, w, 3)).astype(np.ubyte)\n",
    "I.reshape(-1, 3).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping isn't enough to provoke numpy to copy the data, all it needs to do is make a new view on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.base is c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another common reshaping task is to add dimension(s) to an existing array. numpy has a special `newaxis` object for this task. This is a powerful idea when combined with numpy's broadcasting rules (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = np.arange(10)\n",
    "# 10 x 1\n",
    "e[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 x 10\n",
    "e[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 x 1 x 10\n",
    "e[np.newaxis, np.newaxis, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is necessary to go back and forth between flat (1d) and multi-dimensional views of an array. The `np.ravel`, `np.flat` functions and `ndarray.flatten` method as well as things like `np.unravel_index` can help with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking & Splitting ndarrays\n",
    "\n",
    "You can combine general ndarrays with the `np.concatenate` and split them with `np.split`. There are also a number of convenience methods for commonly used shapes.\n",
    "\n",
    " * `_r`\n",
    " * `_c`\n",
    " * `hstack`\n",
    " * `vstack`\n",
    " * `hsplit`\n",
    " * `vsplit`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_r` translates slice objects to concatenation along the first axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.r_[np.array([1,2,3]), 0, 0, np.array([4,5,6])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_c` translates slice objects to concatenation along the second axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.c_[np.array([1,2,3]), np.array([4,5,6])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`hstack`  and `vstack` do something similar, all 4 are basically ways of calling the more generic `np.concatenate` or `np.stack` functions for specific cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In higher dimensions `concatenate` or `stack` should do what you need, but you need to manually tell it which axis to use for the stacking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.array([1,2,3]), [0], [0], np.array([4, 5, 6])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate((np.array([[1, 2, 3]]).T, np.array([[4, 5, 6]]).T), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.split` goes in the opposite direction. It will try to produce sub-arrays of equal size. Again there are `hsplit` and `vsplit` variants for common use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(np.arange(64).reshape((8, 8)), 2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.split(np.arange(64).reshape((8, 8)), 2, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also `np.tile`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.array([[1,0],[0,1]]), (4, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Universal Functions (ufuncs)\n",
    "\n",
    "The real reason for using numpy is so you can do numerical operations, _quickly_. Python uses a concept called `ufuncs` or universal function. A ufunc is a function which operates on `ndarrays` element-by-element. More formally, a `ufunc` is a vectorized wrapper around a function which can do a transformation on an `ndarray` and produces another `ndarray`. This element by element behaviour is fundamentally different from the usual python behaviour.\n",
    "\n",
    "The key to writing fast numeric python code is: **Avoid for & while loops as far as you can, use numpy ufuncs as far as possible**\n",
    "\n",
    "\n",
    "Lets start with basic arithmetic operations. Numpy can use it's internal broadcasting to do these quickly and efficiently\n",
    "\n",
    "The usual operations are available\n",
    "\n",
    "  * +: addition\n",
    "  * -: subtraction\n",
    "  * *: multiplication\n",
    "  * /: division\n",
    "  * //: integer division\n",
    "  * **: power operator\n",
    "  * %: modulo\n",
    "\n",
    "Remember operations are element by element, and you can build up more complicated expressions as you go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = np.linspace(0, 1, 100)\n",
    "\n",
    "(la ** 2 + la) / (la + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Try to calculate the terms of this sum as an `ndarray`\n",
    "$$\n",
    "\\sqrt{12}\\sum_{k=0}^{10}\\frac{(-3)^{-k}}{2k+1}\n",
    "$$\n",
    "\n",
    "_Hints_: Think term by term. `np.arange(10)` will give you an `ndarray` of k values, next raise `-3. * np.ones(k.shape)` to those powers. If you can calculate the terms you can use the `.sum()` method to sum them all up. How close to $\\pi$ did you get?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The operators we were using `+,-,/,...` actually correspond to functions (`ufuncs`)\n",
    "\n",
    "|operator|function|description|\n",
    "|--------|--------|-----------|\n",
    "| + | np.add | Addition |\n",
    "| - | np.subtract | Subtraction |\n",
    "| - | np.negative | Unary negation |\n",
    "| * | np.multiply | Multiplication |\n",
    "| / | np.division | Ordinary floating point division |\n",
    "| // | np.floor_divide | floor (integer) division |\n",
    "| % | np.mod | Modulo/Remainder division |\n",
    "\n",
    "You can use either syntax, but in the function notation there are lots more functions to play with e.g.\n",
    "\n",
    "| function | description |\n",
    "|----------|-------------|\n",
    "| np.sin   | sin function |\n",
    "| np.cos   | cos function |\n",
    "| np.tan   | tan function |\n",
    "| np.abs   | absolute value |\n",
    "| np.exp   | exponential |\n",
    "| np.log   | natural log |\n",
    "| np.log2  | log base 2 |\n",
    "| np.log10 | log base 10 |\n",
    "|  ...     |    ...      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = np.linspace(0, 2*np.pi, 25)\n",
    "p2 = np.sin(p1)\n",
    "p2\n",
    "\n",
    "# p2 sin of p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = np.linspace(0, 1, 10) + np.linspace(1, 2, 10)*1j\n",
    "q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate Functions\n",
    "\n",
    "Aggregate functions take an `ndarray` and reduce it along one (or more) axes. We used `.sum()` above, but another example would be taking an array of numbers and calculating the mean value..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = np.linspace(0, 10, 100)\n",
    "r1.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are lots of aggregate functions\n",
    "\n",
    "  * `min`: Minumum value\n",
    "  * `max`: Maximum value\n",
    "  * `sum`: Sum values\n",
    "  * `prod`: Product of values\n",
    "  * `mean`: Arthmetic mean\n",
    "  * `std`: Standard deviation\n",
    "  * `var`: Variance\n",
    "  * `argmin`: indices of the minimum value\n",
    "  * `argmax`: indices of the maximum value\n",
    "  * `all`: is a condition true in all elements\n",
    "  * `any`: is a condition true in any elements\n",
    "  \n",
    "  The default is to reduce along all axes, if you want to reduce along a specific axis you can pass that as an argument (the axes you specify are the ones which get squashed) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = np.arange(50)\n",
    "s2 = s1.reshape(5,10)\n",
    "s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.mean(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For binary operations (e.g. addition) you can also do reduction, so starting from\n",
    "\n",
    "[1, 3, 5, 7, 9]\n",
    "\n",
    "`np.add.reduce` will add 1 to 3, add that to 5 and so on, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.arange(1, 10, 2)\n",
    "np.add.reduce(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N.B. In this case we used a function from the module and passed in our ndarray."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Exercise**: Find the value closest to a particular number in an array (try using `np.abs` and `np.argmin`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(47)\n",
    "a = rng.normal(size=50)\n",
    "scalar=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also has lots of other utility functions, here are a few commonly used ones\n",
    "\n",
    "  * `np.bincount`: Count number of occurences of each value in an array of non negative ints\n",
    "  * `np.allclose`: Check if two arrays are equal within some tolerance\n",
    "  * `np.pad`: Padding arrays\n",
    "  * `np.unique`: Find unique elements within an array\n",
    "  * `np.percentile`: Compute percentiles along some axis\n",
    "  * `np.sort`: Sort (various algorithms), `np.argsort` returns indices of for sorting\n",
    "  * `np.where`: Return elements matching some condition\n",
    "  \n",
    "and __[many](https://numpy.org/doc/stable/reference/routines.html)__ others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(np.random.binomial(10, p=0.3, size=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Broadcasting\n",
    "\n",
    "`numpy` likes to operate element by element, but not all arrays are the same size. To work around this, `numpy` implements a set of rules called `broadcasting` to make `ndarray`s conform whenever possible. This is great news; it means you don't have to worry about doing that yourself, but it is important to understand the rules so that you know how `numpy` will behave when combining differnt shaped `ndarrays`. To get the idea, think of\n",
    "```python\n",
    "np.arange(10) * 5\n",
    "```\n",
    "`numpy` wants to operate element-by-element, but `5` isn't an `ndarray`, it's just a number. If we could prompte 5 to be a $1\\times 5$ `ndarray` with 5's in in every place `numpy` would be happy. This is the basic idea of broadcasting, explicitly\n",
    "\n",
    "1. Given two arrays of different dimensions, prepend dimensions of length 1 to the shape of the smaller array until they have the same number of dimensions\n",
    "1. Any dimensions of size 1 are repeated/reused as often as needed to make shapes conform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(15)\n",
    "a = a.reshape(3, 5)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(5)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I want to multiply these two `ndarray`s, `b` has fewer dimensions (1 vs. 2) so a dimension of length 1 will be prepended to `b`. `b` will then be repeated 3 times to conform with the shape of a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to be explicit, that operation does something lie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "btmp = np.repeat(b[np.newaxis, :], 3, axis=0)\n",
    "a *  btmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To take a more complicated example..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(24).reshape(2,1,3,4)\n",
    "b = np.arange(8).reshape(2,1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the number of dimensions are compared; `a` has dimension 4, `b` has dimension 3, so 1 is prepended to the shape of `b`, making it `(1, 2, 1, 4)`. Next we compare the dimensions from right to left. The last dimension matches so nothing is done there. The second to last dimension of `a` is larger then that of `b` so `b` will be repeated 3 times along that axis to make them match. For the next dimension, `b` is larger than `a`, so `a` will be repeated twice, and for the final axis `a` is larger than `b` so `b` will be repeated twice to make them match. Bringing that all together, the final result should have shape `(2,2,3,4)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(a+b).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random\n",
    "\n",
    "Numpy has a few important submodules but `np.random` is probably the most important. As you might expect, it lets you work with random numbers. It can sample from different distributions (30+ available), handle permutations and do lots of other handy things.\n",
    "\n",
    "`numpy.random` uses the concept of a `Generators` to implement sampling. The idea is you create a generator object then call methods on that generator to sample from the various distributions. The original `Generator` will normally get it's entropy from a (hopefully reliable source) then you can keep asking it for the `__next__` random elements distributed however you need.\n",
    "\n",
    "(The generator interface to `numpy.random` is relatively recent, occasionally you will still see me explicity call functions of the submodule as I did above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(47)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've seeded the `Generator` with a specific value so the results are reporoducible but normally you would just call `np.random.default_rng()` to get a random value from the OS. Now we can sample from various distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.normal(5.0, 1.0, (64, 64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The binomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.binomial(10, .5, size=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 random integers between 10 and 20 (discrete uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng.integers(10, 20, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.random` also has functions for shuffling arrays in-place (`np.shuffle`) and selecting elements at random from `ndarrays` (`np.choice`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "np.random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10)\n",
    "np.random.choice(a, 3, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also weight the selections in `np.choice` with probabilities. e.g. Here are the letter frequencies of ordinary english text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_freq = {' ': 0.19266420666588144,\n",
    " 'e': 0.09680968984305797,\n",
    " 't': 0.07140241019840815,\n",
    " 'a': 0.06361581392196947,\n",
    " 'o': 0.06183938572048604,\n",
    " 'i': 0.05349452953695084,\n",
    " 'n': 0.0521037201730283,\n",
    " 'h': 0.051232447485652234,\n",
    " 's': 0.049280151278754014,\n",
    " 'r': 0.04524648142979075,\n",
    " 'd': 0.03375374929612461,\n",
    " 'l': 0.03124157971419029,\n",
    " 'u': 0.02392934301198968,\n",
    " 'm': 0.021518821910249234,\n",
    " 'w': 0.020208685943305965,\n",
    " 'c': 0.02004895261728702,\n",
    " 'f': 0.016262143363080305,\n",
    " 'y': 0.016250849087503207,\n",
    " 'g': 0.013559584564274916,\n",
    " 'p': 0.012933559003715817,\n",
    " ',': 0.012259129404969158,\n",
    " '.': 0.01200420147051468,\n",
    " 'b': 0.011160357738111564,\n",
    " 'v': 0.0076220225466009876,\n",
    " 'k': 0.006392559976636984,\n",
    " 'x': 0.001353699601312072,\n",
    " 'j': 0.0008260955850676769,\n",
    " 'q': 0.0006663622590487316,\n",
    " 'z': 0.00031946665203789066\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use those relative frequency values as probabilities (they sum to ~1) and generate a random sample of letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = np.fromiter(letter_freq.keys(),dtype='<U1')\n",
    "probabilities = np.fromiter(letter_freq.values(), dtype=float)\n",
    "chosen = np.random.choice(letters, 1000, p=probabilities)\n",
    "''.join(chosen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Also\n",
    "\n",
    "  * [np.linalg](https://numpy.org/doc/stable/reference/routines.linalg.html): Linear algebra operations\n",
    "  * [np.fft](https://numpy.org/doc/stable/reference/routines.fft.html): Fast Fourier Transforms\n",
    "  * [Sorting, Searching and Counting](https://numpy.org/doc/stable/reference/routines.sort.html): Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "1. Create an `ndarray` `X` random numbers between 0 and 1 (uniformly distributed) with shape `(5, 2)`. We will interprate X as a list of 10 2D coordinates x & y.\n",
    "2. Use `np.newaxis` and broadcasting to generate a `(5, 5, 2)` array of the squared distances between the each pair of points.\n",
    "3. Use argsort to build a (10x10) array of nearest neighbours for each point. The values in the array will be integers corresponding to the rows of the original `X`. e.g the first row might look like [0, 3, 2, 1, 4], meaning the nearest point is the point itself (`0` in this case), then the point in the 4th row and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
